# Testy Diarization i Transkrypcji na ≈ªywo

Ten folder zawiera testowe implementacje system√≥w transkrypcji i rozpoznawania m√≥wc√≥w w czasie rzeczywistym.

## üìÅ Pliki

### 1. `test_chunking_gradio_diarization.py`
**Transkrypcja + Diarization (rozpoznawanie m√≥wc√≥w)**

- **Funkcjonalno≈õƒá:**
  - Streaming audio w czasie rzeczywistym z mikrofonu
  - Automatyczne chunkowanie nagrania (10 sekund z 2 sekundami overlap)
  - Transkrypcja i diarization przez Deepgram API LUB lokalne whisper-diarization
  - Wy≈õwietlanie transkrypcji z przypisanymi m√≥wcami (Speaker 0, Speaker 1, ...)
  - Automatyczne od≈õwie≈ºanie UI co 2 sekundy
  - Progress bar dla przetwarzania chunk√≥w

- **Mechanizm chunkowania:**
  - Ka≈ºdy chunk: 10 sekund audio
  - Overlap: 2 sekundy miƒôdzy chunkami (aby nie ucinaƒá zda≈Ñ)
  - Przyk≈Çad: Chunk 1: 0-10s, Chunk 2: 8-18s, Chunk 3: 16-26s
  - Automatyczne filtrowanie duplikat√≥w z obszaru overlap

- **Diarization:**
  - **Deepgram API** (domy≈õlnie, `USE_DEEPGRAM=true`):
    - Model: nova-2
    - Jƒôzyk: polski (pl)
    - Parametry: `diarize=true`, `utterances=true`, `smart_format=true`
    - Automatyczne wykrywanie m√≥wc√≥w w odpowiedzi API
  - **whisper-diarization** (lokalne, `USE_DEEPGRAM=false`):
    - Wymaga CUDA GPU (lub CPU jako fallback)
    - Wykrywa architekturƒô GPU i dostosowuje `compute_type` (float16/float32)
    - Automatyczny fallback na CPU przy b≈Çƒôdach CUDA
    - Wymaga zewnƒôtrznych repozytori√≥w: `whisper-diarization` i `ctc-forced-aligner`

- **Port:** 7861

### 2. `test_chunking_gradio.py`
**Transkrypcja + Rozpoznawanie R√≥l przez LLM**

- **Funkcjonalno≈õƒá:**
  - Streaming audio w czasie rzeczywistym z mikrofonu
  - Automatyczne chunkowanie nagrania (10 sekund, bez overlap)
  - Transkrypcja przez Groq Whisper API (model: whisper-large-v3)
  - Rozpoznawanie r√≥l (lekarz/pacjent) przez LLM (Gemini Flash przez OpenRouter)
  - Wy≈õwietlanie transkrypcji z przypisanymi rolami
  - Automatyczne od≈õwie≈ºanie UI co 2 sekundy
  - Progress bar dla przetwarzania chunk√≥w

- **Mechanizm chunkowania:**
  - Ka≈ºdy chunk: 10 sekund audio
  - Brak overlap (prostsze, ale mo≈ºe ucinaƒá zdania)
  - Przyk≈Çad: Chunk 1: 0-10s, Chunk 2: 10-20s, Chunk 3: 20-30s

- **Rozpoznawanie r√≥l:**
  - LLM analizuje transkrypcjƒô i rozpoznaje role na podstawie tre≈õci
  - Wykrywa lekarza i pacjenta w rozmowie medycznej
  - Zwraca pewno≈õƒá rozpoznania (wysoka/≈õrednia/niska)

- **Port:** 7860

## üöÄ Instalacja

1. **Zainstaluj zale≈ºno≈õci:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Skonfiguruj zmienne ≈õrodowiskowe:**
   Utw√≥rz plik `.env.test` w g≈Ç√≥wnym folderze projektu z:
   ```env
   # Dla test_chunking_gradio.py
   GROQ_API_KEY=your_groq_api_key
   OPENROUTER_API_KEY=your_openrouter_api_key
   LANG=pl
   
   # Dla test_chunking_gradio_diarization.py (Deepgram)
   DEEPGRAM_API_KEY=your_deepgram_api_key
   USE_DEEPGRAM=true
   
   # Dla test_chunking_gradio_diarization.py (whisper-diarization lokalne)
   USE_DEEPGRAM=false
   WHISPER_DIARIZATION_DIR=./whisper-diarization
   DEVICE=cuda
   WHISPER_MODEL=small
   ```

3. **Uruchom aplikacjƒô:**
   ```bash
   # Diarization
   python test_chunking_gradio_diarization.py
   
   # Rozpoznawanie r√≥l
   python test_chunking_gradio.py
   ```

## üîß Konfiguracja

### `test_chunking_gradio_diarization.py`
- `CHUNK_SECONDS=10` - d≈Çugo≈õƒá chunka (sekundy)
- `CHUNK_OVERLAP_SECONDS=2.0` - overlap miƒôdzy chunkami (sekundy)
- `USE_DEEPGRAM=true/false` - wyb√≥r silnika diarization
- `DEVICE=cuda/cpu` - urzƒÖdzenie dla whisper-diarization
- `WHISPER_MODEL=small/medium/large-v3` - model Whisper

### `test_chunking_gradio.py`
- `CHUNK_SECONDS=10` - d≈Çugo≈õƒá chunka (sekundy)
- `GEMINI_FLASH_MODEL` - model LLM (domy≈õlnie: google/gemini-2.5-flash-lite)

## üìù Mechanizm Chunkowania

### Wersja z overlap (`test_chunking_gradio_diarization.py`):
```
Chunk 1: [0s -------- 10s]
Chunk 2:        [8s -------- 18s]  (2s overlap)
Chunk 3:               [16s -------- 26s]  (2s overlap)
```

**Zalety:**
- Nie ucina zda≈Ñ w po≈Çowie
- Lepsze rozpoznawanie m√≥wc√≥w na granicach chunk√≥w
- P≈Çynniejsza transkrypcja

**Wady:**
- Wiƒôksze zu≈ºycie zasob√≥w (przetwarzanie overlap)
- Wymaga filtrowania duplikat√≥w

### Wersja bez overlap (`test_chunking_gradio.py`):
```
Chunk 1: [0s -------- 10s]
Chunk 2:              [10s -------- 20s]
Chunk 3:                         [20s -------- 30s]
```

**Zalety:**
- Prostsze w implementacji
- Mniejsze zu≈ºycie zasob√≥w

**Wady:**
- Mo≈ºe ucinaƒá zdania w po≈Çowie
- Gorsze rozpoznawanie na granicach chunk√≥w

## üéØ Diarization

### Deepgram API (zalecane)
- ‚úÖ Szybkie (1-2 sekundy na chunk)
- ‚úÖ Nie wymaga GPU
- ‚úÖ Dobre rozpoznawanie m√≥wc√≥w
- ‚ùå Wymaga klucza API (p≈Çatne)

### whisper-diarization (lokalne)
- ‚úÖ Darmowe (lokalne przetwarzanie)
- ‚úÖ Dobre rozpoznawanie m√≥wc√≥w
- ‚ùå Wymaga CUDA GPU (lub wolne na CPU)
- ‚ùå Wymaga zewnƒôtrznych repozytori√≥w
- ‚ùå Wolniejsze (10-60 sekund na chunk)

## üìä Status

**To jest wersja testowa** - nie trafi do g≈Ç√≥wnego projektu. Zosta≈Ça utworzona w celu:
- Testowania mechanizm√≥w chunkowania audio
- Testowania r√≥≈ºnych silnik√≥w diarization
- Eksperymentowania z rozpoznawaniem m√≥wc√≥w i r√≥l
- Oceny wydajno≈õci i jako≈õci transkrypcji

## üîç Co zosta≈Ço zaimplementowane

1. ‚úÖ Streaming audio w czasie rzeczywistym (sounddevice)
2. ‚úÖ Automatyczne chunkowanie z overlap (2 sekundy)
3. ‚úÖ Integracja z Deepgram API dla diarization
4. ‚úÖ Integracja z whisper-diarization (lokalne)
5. ‚úÖ Automatyczne wykrywanie architektury GPU
6. ‚úÖ Fallback na CPU przy b≈Çƒôdach CUDA
7. ‚úÖ Progress bar i status przetwarzania
8. ‚úÖ Automatyczne od≈õwie≈ºanie UI
9. ‚úÖ Filtrowanie duplikat√≥w z overlap
10. ‚úÖ Rozpoznawanie r√≥l przez LLM (test_chunking_gradio.py)

## ‚ö†Ô∏è Uwagi

- Pliki wymagajƒÖ pliku `.env.test` w g≈Ç√≥wnym folderze projektu (nie w `diarization_test`)
- `whisper-diarization` wymaga dodatkowych zale≈ºno≈õci i zewnƒôtrznych repozytori√≥w
- Deepgram API wymaga klucza API (mo≈ºe byƒá p≈Çatne)
- Testy sƒÖ przeznaczone do eksperymentowania, nie do produkcji

